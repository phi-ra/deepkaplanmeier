{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional Kaplan Meier\n",
    "\n",
    "## Stage 2: Dependent Censoring\n",
    "\n",
    "Before running the notebook make sure that:\n",
    "\n",
    "1. Created a python/conda environment according to the specifications\n",
    "2. Set your working directory (`project_dir`) to the directory where you unpacked the .zip file\n",
    "3. You might want to add a shebang line to the ./utils (however using it from notebooks with a specified environment should work as well)\n",
    "\n",
    "The notebook genereates data, trains models and saves them into the ./data directory. Note that at times you will need to overwrite existing files (this is to ensure that you do not accidentally overwrite files that took a long time training - aka. model weights)\n",
    "\n",
    "See R-Scrips for visualisations (by default, all visualisations should already be in the zip folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Housekeeping\n",
    "import os\n",
    "os.chdir(project_dir)\n",
    "\n",
    "# For data generation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import gamma, bernoulli, multinomial\n",
    "from scipy.integrate import simps\n",
    "from scipy.special import expit\n",
    "from itertools import product as itp\n",
    "\n",
    "# For standard survival modelling\n",
    "from lifelines import KaplanMeierFitter, CoxPHFitter\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Model loading\n",
    "import tensorflow as tf\n",
    "\n",
    "# Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "tf.keras.utils.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from main.utils.conditional_km import DeepKaplanMeier, SimpleDeepKaplanCensoring\n",
    "from main.utils.metrics import calculate_concordance_surv\n",
    "train_ = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running conditional and nonlinear conditional model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_ = 3000\n",
    "seed_ = 42\n",
    "\n",
    "np.random.seed(seed_)\n",
    "x_1 = np.random.exponential(0.1, size=size_)\n",
    "x_2 = np.random.normal(10, np.sqrt(5), size=size_)\n",
    "x_3 = np.random.poisson(5, size=size_)\n",
    "\n",
    "features = np.array([x_1, x_2, x_3]).T\n",
    "\n",
    "# Arrange Targets\n",
    "survial_model = -3.14*x_1 + 0.318*x_2 + 2.72*x_3\n",
    "\n",
    "true_survival_time = gamma.rvs(survial_model, scale=1, random_state=seed_)\n",
    "ceiling_surv_ = np.ceil(true_survival_time)\n",
    "\n",
    "censoring_transformed = np.minimum(2*(survial_model/survial_model.max()),1)\n",
    "\n",
    "censored_instances = np.random.uniform(size=size_) > (censoring_transformed)\n",
    "censored_surv = [np.ceil(np.random.uniform()*val_) for val_ in ceiling_surv_[censored_instances]]\n",
    "\n",
    "observed_survival = ceiling_surv_.copy()\n",
    "observed_survival[censored_instances] = censored_surv\n",
    "\n",
    "variable_dict = dict({'true_survival': ceiling_surv_,\n",
    "                      'observed_survival': observed_survival, \n",
    "                      'censoring': censored_instances,\n",
    "                      'features' :  features})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaplan_meier = KaplanMeierFitter()\n",
    "kaplan_meier.fit(variable_dict['observed_survival'], \n",
    "                 ~variable_dict['censoring'])\n",
    "\n",
    "kaplan_meier_survival = kaplan_meier.survival_function_\n",
    "\n",
    "# Export for plotting\n",
    "(kaplan_meier_survival.reset_index()\n",
    "                      .to_csv('data/dependent_censoring/kaplan_meier_linearly_dep_censoring_1.csv', \n",
    "                      index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-20 17:50:03.704010: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-10-20 17:50:03.704114: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set up model\n",
    "total_periods = int(variable_dict['observed_survival'].max())\n",
    "\n",
    "deep_model_linear_dep = DeepKaplanMeier(total_periods)\n",
    "deep_model_linear_dep.compile_model((3, ), [12,12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No file or directory found at data/models/keras_model_simple_lin_cens_.keras",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m/Users/philippratz/Documents/Uni/PhD/UQAM/research/joint_estimation/cond_km/main/notebooks/dependent_censoring.ipynb Cell 10\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/philippratz/Documents/Uni/PhD/UQAM/research/joint_estimation/cond_km/main/notebooks/dependent_censoring.ipynb#X11sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     mod_ \u001b[39m=\u001b[39m deep_model_linear_dep\u001b[39m.\u001b[39mmodel\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/philippratz/Documents/Uni/PhD/UQAM/research/joint_estimation/cond_km/main/notebooks/dependent_censoring.ipynb#X11sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/philippratz/Documents/Uni/PhD/UQAM/research/joint_estimation/cond_km/main/notebooks/dependent_censoring.ipynb#X11sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     mod_ \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mmodels\u001b[39m.\u001b[39;49mload_model(\u001b[39m'\u001b[39;49m\u001b[39mdata/models/keras_model_simple_lin_cens_.keras\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/Documents/Uni/PhD/UQAM/computing/tens_env/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Documents/Uni/PhD/UQAM/computing/tens_env/lib/python3.8/site-packages/keras/saving/save.py:206\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(filepath_str, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    205\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39mexists(filepath_str):\n\u001b[0;32m--> 206\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mNo file or directory found at \u001b[39m\u001b[39m{\u001b[39;00mfilepath_str\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    208\u001b[0m   \u001b[39mif\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39misdir(filepath_str):\n\u001b[1;32m    209\u001b[0m     \u001b[39mreturn\u001b[39;00m saved_model_load\u001b[39m.\u001b[39mload(filepath_str, \u001b[39mcompile\u001b[39m, options)\n",
      "\u001b[0;31mOSError\u001b[0m: No file or directory found at data/models/keras_model_simple_lin_cens_.keras"
     ]
    }
   ],
   "source": [
    "# Fit model\n",
    "if train_:\n",
    "    deep_model_linear_dep.fit_model(variable_dict['features'],\n",
    "                                variable_dict['observed_survival'].astype(int), \n",
    "                                variable_dict['censoring'],\n",
    "                                epochs=100, \n",
    "                                verbose=False, \n",
    "                                batch_size=128\n",
    "                                )\n",
    "    mod_ = deep_model_linear_dep.model\n",
    "\n",
    "else:\n",
    "    mod_ = tf.keras.models.load_model('data/models/keras_model_simple_lin_cens_.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-20 17:12:48.678042: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/94 [..............................] - ETA: 1:12\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 3/94 [..............................] - ETA: 2s  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 7/94 [=>............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r11/94 [==>...........................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/94 [===>..........................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19/94 [=====>........................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r23/94 [======>.......................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r27/94 [=======>......................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/94 [========>.....................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r35/94 [==========>...................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r39/94 [===========>..................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r43/94 [============>.................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r47/94 [==============>...............] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r51/94 [===============>..............] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r55/94 [================>.............] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r59/94 [=================>............] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r63/94 [===================>..........] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r67/94 [====================>.........] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r71/94 [=====================>........] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r75/94 [======================>.......] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r78/94 [=======================>......] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r82/94 [=========================>....] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r86/94 [==========================>...] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r90/94 [===========================>..] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r94/94 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r94/94 [==============================] - 2s 18ms/step\n",
      "The concordance index is: 0.806\n"
     ]
    }
   ],
   "source": [
    "preds_ = mod_.predict(variable_dict['features'])\n",
    "preds_ = pd.DataFrame(list(map(np.ravel, preds_)))\n",
    "\n",
    "# Predictions are a list for each timeperiod, flatten and create exportable dataframe\n",
    "ckm_df = (preds_\n",
    "          .reset_index()\n",
    "          .rename(columns={'index':'timeline'}))\n",
    "# Export\n",
    "ckm_df.to_csv('data/dependent_censoring/ckm_linear_dependent_censoring.csv', \n",
    "              index=False)\n",
    "\n",
    "nom_, denom_, val_ = calculate_concordance_surv(variable_dict['observed_survival'], \n",
    "                                                variable_dict['censoring'], \n",
    "                                                preds_)\n",
    "print(f\"The concordance index is: {np.round(val_, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jy/l1h7n_nx6sl3h96lm_0n3ppc0000gn/T/ipykernel_6846/1256711721.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  true_data = (true_data\n"
     ]
    }
   ],
   "source": [
    "true_data = (pd.DataFrame({'surv_time' : variable_dict['true_survival']})\n",
    "             .groupby('surv_time')\n",
    "             .agg({'surv_time': 'count'})\n",
    "             .rename(columns={'surv_time': 'failures'})\n",
    "             .reset_index())\n",
    "\n",
    "true_data['relative'] = true_data.failures / size_\n",
    "true_data['survival'] = 1-np.cumsum(true_data.relative)\n",
    "true_data = true_data[['surv_time', 'survival']]\n",
    "true_data = (true_data\n",
    "             .append(pd.DataFrame({'surv_time': [0], 'survival':[1]}))\n",
    "             .reset_index()\n",
    "             .sort_values('surv_time'))\n",
    "\n",
    "(true_data[['surv_time', 'survival']].rename(columns={'surv_time': 'timeline'})\n",
    "                                     .to_csv('data/dependent_censoring/true_data_linear_censoring.csv', \n",
    "                                     index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lifelines.CoxPHFitter: fitted with 3000 total observations, 800 right-censored observations>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cox model\n",
    "cox_df = (pd.DataFrame(\n",
    "                       np.column_stack((variable_dict['observed_survival'],\n",
    "                                        ~variable_dict['censoring'],\n",
    "                                        variable_dict['features']))\n",
    "                       ))\n",
    "cox_df.columns = ['surv', 'cens', 'feat_1', 'feat_2', 'feat_3']\n",
    "\n",
    "cph = CoxPHFitter()\n",
    "cph.fit(cox_df, duration_col='surv', event_col='cens')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cox concordance index for Linear model is: 0.805\n"
     ]
    }
   ],
   "source": [
    "print(f\"Cox concordance index for Linear model is: {np.round(cph.concordance_index_,3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nonlinear Hazards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_ = 3000\n",
    "seed_ = 42\n",
    "\n",
    "np.random.seed(seed_)\n",
    "x_1 = np.random.exponential(0.1, size=size_)\n",
    "x_2 = np.random.normal(10, np.sqrt(5), size=size_)\n",
    "x_3 = np.random.poisson(5, size=size_)\n",
    "\n",
    "features = np.array([x_1, x_2, x_3]).T\n",
    "\n",
    "# Arrange Targets\n",
    "survial_model = np.sin(x_1)*3.14 + 0.318*x_2 + 2.72*np.abs(np.cos(x_3))\n",
    "\n",
    "true_survival_time = gamma.rvs(survial_model, scale=1, random_state=seed_)\n",
    "ceiling_surv_ = np.ceil(true_survival_time)\n",
    "\n",
    "censoring_transformed = np.minimum(2*(survial_model/survial_model.max()),1)\n",
    "\n",
    "censored_instances = np.random.uniform(size=size_) > (censoring_transformed)\n",
    "censored_surv = [np.ceil(np.random.uniform()*val_) for val_ in ceiling_surv_[censored_instances]]\n",
    "\n",
    "observed_survival = ceiling_surv_.copy()\n",
    "observed_survival[censored_instances] = censored_surv\n",
    "\n",
    "variable_dict = dict({'true_survival': ceiling_surv_,\n",
    "                      'observed_survival': observed_survival, \n",
    "                      'censoring': censored_instances,\n",
    "                      'features' :  features})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some test data as well\n",
    "size_ = 1000\n",
    "seed_ = 42\n",
    "\n",
    "np.random.seed(seed_)\n",
    "x_1 = np.random.exponential(0.1, size=size_)\n",
    "x_2 = np.random.normal(10, np.sqrt(5), size=size_)\n",
    "x_3 = np.random.poisson(5, size=size_)\n",
    "\n",
    "features = np.array([x_1, x_2, x_3]).T\n",
    "\n",
    "# Arrange Targets\n",
    "survial_model = np.sin(x_1)*3.14 + 0.318*x_2 + 2.72*np.abs(np.cos(x_3))\n",
    "\n",
    "true_survival_time = gamma.rvs(survial_model, scale=1, random_state=seed_)\n",
    "ceiling_surv_ = np.ceil(true_survival_time)\n",
    "\n",
    "censoring_transformed = np.minimum(2*(survial_model/survial_model.max()),1)\n",
    "\n",
    "censored_instances = np.random.uniform(size=size_) > (censoring_transformed)\n",
    "censored_surv = [np.ceil(np.random.uniform()*val_) for val_ in ceiling_surv_[censored_instances]]\n",
    "\n",
    "observed_survival = ceiling_surv_.copy()\n",
    "observed_survival[censored_instances] = censored_surv\n",
    "\n",
    "variable_dict_test = dict({'true_survival': ceiling_surv_,\n",
    "                      'observed_survival': observed_survival, \n",
    "                      'censoring': censored_instances,\n",
    "                      'features' :  features})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lifelines.CoxPHFitter: fitted with 3000 total observations, 104 right-censored observations>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cox model\n",
    "cox_df = (pd.DataFrame(\n",
    "                       np.column_stack((variable_dict['observed_survival'],\n",
    "                                        ~variable_dict['censoring'],\n",
    "                                        variable_dict['features']))\n",
    "                       ))\n",
    "cox_df.columns = ['surv', 'cens', 'feat_1', 'feat_2', 'feat_3']\n",
    "\n",
    "cox_df_test = (pd.DataFrame(\n",
    "                       np.column_stack((variable_dict_test['observed_survival'],\n",
    "                                        ~variable_dict_test['censoring'],\n",
    "                                        variable_dict_test['features']))\n",
    "                       ))\n",
    "cox_df_test.columns = ['surv', 'cens', 'feat_1', 'feat_2', 'feat_3']\n",
    "\n",
    "cph = CoxPHFitter()\n",
    "cph.fit(cox_df, duration_col='surv', event_col='cens')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cox concordance index is: 0.59\n"
     ]
    }
   ],
   "source": [
    "print(f\"Cox concordance index is: {np.round(cph.concordance_index_,2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_:\n",
    "    # Make model quite flexible \n",
    "    tf.keras.utils.set_random_seed(42)\n",
    "\n",
    "    # Set up model\n",
    "    total_periods = int(variable_dict['observed_survival'].max())\n",
    "\n",
    "    deep_model_simple = DeepKaplanMeier(total_periods)\n",
    "    deep_model_simple.compile_model((3, ), [20,20,20], preoutput=12)\n",
    "\n",
    "    # Fit model\n",
    "    deep_model_simple.fit_model(variable_dict['features'],\n",
    "                                variable_dict['observed_survival'].astype(int), \n",
    "                                variable_dict['censoring'],\n",
    "                                epochs=150, \n",
    "                                verbose=False, \n",
    "                                batch_size=128\n",
    "                                )\n",
    "    mod_s = deep_model_linear_dep.model\n",
    "else:\n",
    "    mod_s = tf.keras.models.load_model('data/model_weights/model_nonlinear_dep_cens.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-20 17:08:39.177835: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/32 [..............................] - ETA: 12s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 8/32 [======>.......................] - ETA: 0s \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/32 [=============>................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r23/32 [====================>.........] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/32 [============================>.] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32/32 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32/32 [==============================] - 1s 12ms/step\n",
      "0.6436078213290981\n"
     ]
    }
   ],
   "source": [
    "preds_test = mod_s.predict(variable_dict_test['features'])\n",
    "preds_test = pd.DataFrame(list(map(np.ravel, preds_test)))\n",
    "\n",
    "nom_, denom_, val_ = calculate_concordance_surv(variable_dict_test['observed_survival'], \n",
    "                                                variable_dict_test['censoring'], \n",
    "                                                preds_test)\n",
    "print(val_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robustness trials with size\n",
    "\n",
    "Here we increase the censoring proportion (by decreasing the scale parameter to 0.75) - see line 17 in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_ = 3000\n",
    "seed_ = 42\n",
    "\n",
    "np.random.seed(seed_)\n",
    "x_1 = np.random.exponential(0.1, size=size_)\n",
    "x_2 = np.random.normal(10, np.sqrt(5), size=size_)\n",
    "x_3 = np.random.poisson(5, size=size_)\n",
    "\n",
    "features = np.array([x_1, x_2, x_3]).T\n",
    "\n",
    "# Arrange Targets\n",
    "survial_model = -3.14*x_1 + 0.318*x_2 + 2.72*x_3\n",
    "\n",
    "true_survival_time = gamma.rvs(survial_model, scale=1, random_state=seed_)\n",
    "ceiling_surv_ = np.ceil(true_survival_time)\n",
    "\n",
    "censoring_transformed = np.minimum(0.75*(survial_model/survial_model.max()),1)\n",
    "\n",
    "censored_instances = np.random.uniform(size=size_) > (censoring_transformed)\n",
    "censored_surv = [np.ceil(np.random.uniform()*val_) for val_ in ceiling_surv_[censored_instances]]\n",
    "\n",
    "observed_survival = ceiling_surv_.copy()\n",
    "observed_survival[censored_instances] = censored_surv\n",
    "\n",
    "variable_dict = dict({'true_survival': ceiling_surv_,\n",
    "                      'observed_survival': observed_survival, \n",
    "                      'censoring': censored_instances,\n",
    "                      'features' :  features})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Censoring proportion is 0.713\n"
     ]
    }
   ],
   "source": [
    "print(f\"Censoring proportion is {np.round(variable_dict['censoring'].mean(), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_:\n",
    "        \n",
    "    tf.keras.utils.set_random_seed(42)\n",
    "\n",
    "    # Set up model\n",
    "    total_periods = int(variable_dict['observed_survival'].max())\n",
    "\n",
    "    model_heavy_cens = DeepKaplanMeier(total_periods)\n",
    "    model_heavy_cens.compile_model((3, ), [12,12], preoutput=12)\n",
    "\n",
    "    # Fit model\n",
    "    model_heavy_cens.fit_model(variable_dict['features'],\n",
    "                                variable_dict['observed_survival'].astype(int), \n",
    "                                variable_dict['censoring'],\n",
    "                                epochs=50, \n",
    "                                verbose=False, \n",
    "                                batch_size=128\n",
    "                                )\n",
    "\n",
    "    mod_hcs = model_heavy_cens.model\n",
    "\n",
    "else:\n",
    "    mod_hcs = tf.keras.models.load_model('data/model_weights/model_heavy_censoring_small.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-20 17:14:09.730747: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/94 [..............................] - ETA: 1:17\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 4/94 [>.............................] - ETA: 1s  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 6/94 [>.............................] - ETA: 2s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r10/94 [==>...........................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r14/94 [===>..........................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r18/94 [====>.........................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/94 [======>.......................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r26/94 [=======>......................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r30/94 [========>.....................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r34/94 [=========>....................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r38/94 [===========>..................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r42/94 [============>.................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r46/94 [=============>................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/94 [==============>...............] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r54/94 [================>.............] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r58/94 [=================>............] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r62/94 [==================>...........] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r66/94 [====================>.........] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r70/94 [=====================>........] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r74/94 [======================>.......] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r78/94 [=======================>......] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r82/94 [=========================>....] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r86/94 [==========================>...] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r90/94 [===========================>..] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r94/94 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r94/94 [==============================] - 3s 21ms/step\n"
     ]
    }
   ],
   "source": [
    "# Run predictions \n",
    "predictions_ckm_hc = mod_hcs.predict(variable_dict['features'])\n",
    "\n",
    "# Predictions are a list for each timeperiod, flatten and create exportable dataframe\n",
    "ckm_df = (pd.DataFrame(list(map(np.ravel, predictions_ckm_hc)))\n",
    "          .reset_index()\n",
    "          .rename(columns={'index':'timeline'}))\n",
    "\n",
    "# Avoid Python specific index issues\n",
    "ckm_df['timeline'] = ckm_df.timeline\n",
    "\n",
    "# Export\n",
    "ckm_df.to_csv('data/dependent_censoring/ckm_pred_heavy_censoring_small.csv', \n",
    "              index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jy/l1h7n_nx6sl3h96lm_0n3ppc0000gn/T/ipykernel_6846/3134575718.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  true_data = (true_data\n"
     ]
    }
   ],
   "source": [
    "true_data = (pd.DataFrame({'surv_time' : variable_dict['true_survival']})\n",
    "             .groupby('surv_time')\n",
    "             .agg({'surv_time': 'count'})\n",
    "             .rename(columns={'surv_time': 'failures'})\n",
    "             .reset_index())\n",
    "\n",
    "true_data['relative'] = true_data.failures / size_\n",
    "true_data['survival'] = 1-np.cumsum(true_data.relative)\n",
    "true_data = true_data[['surv_time', 'survival']]\n",
    "true_data = (true_data\n",
    "             .append(pd.DataFrame({'surv_time': [0], 'survival':[1]}))\n",
    "             .reset_index()\n",
    "             .sort_values('surv_time'))\n",
    "\n",
    "(true_data[['surv_time', 'survival']].rename(columns={'surv_time': 'timeline'})\n",
    "                                     .to_csv('data/dependent_censoring/heavy_censoring_true.csv', \n",
    "                                     index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaplan_meier = KaplanMeierFitter()\n",
    "kaplan_meier.fit(variable_dict['observed_survival'], \n",
    "                 ~variable_dict['censoring'])\n",
    "\n",
    "kaplan_meier_survival = kaplan_meier.survival_function_\n",
    "\n",
    "# Export for plotting\n",
    "(kaplan_meier_survival.reset_index()\n",
    "                      .to_csv('data/dependent_censoring/km_heavy_censoring.csv', \n",
    "                      index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Increase Dataset size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_ = 12000\n",
    "seed_ = 42\n",
    "\n",
    "np.random.seed(seed_)\n",
    "x_1 = np.random.exponential(0.1, size=size_)\n",
    "x_2 = np.random.normal(10, np.sqrt(5), size=size_)\n",
    "x_3 = np.random.poisson(5, size=size_)\n",
    "\n",
    "features = np.array([x_1, x_2, x_3]).T\n",
    "\n",
    "# Arrange Targets\n",
    "survial_model = -3.14*x_1 + 0.318*x_2 + 2.72*x_3\n",
    "\n",
    "true_survival_time = gamma.rvs(survial_model, scale=1, random_state=seed_)\n",
    "ceiling_surv_ = np.ceil(true_survival_time)\n",
    "\n",
    "censoring_transformed = np.minimum(0.75*(survial_model/survial_model.max()),1)\n",
    "\n",
    "censored_instances = np.random.uniform(size=size_) > (censoring_transformed)\n",
    "censored_surv = [np.ceil(np.random.uniform()*val_) for val_ in ceiling_surv_[censored_instances]]\n",
    "\n",
    "observed_survival = ceiling_surv_.copy()\n",
    "observed_survival[censored_instances] = censored_surv\n",
    "\n",
    "variable_dict = dict({'true_survival': ceiling_surv_,\n",
    "                      'observed_survival': observed_survival, \n",
    "                      'censoring': censored_instances,\n",
    "                      'features' :  features})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_:\n",
    "    # Set up model\n",
    "    total_periods = int(variable_dict['observed_survival'].max())\n",
    "\n",
    "    model_heavy_cens = DeepKaplanMeier(total_periods)\n",
    "    model_heavy_cens.compile_model((3, ), [24,24,24], preoutput=24)\n",
    "\n",
    "    # Fit model\n",
    "    model_heavy_cens.fit_model(variable_dict['features'],\n",
    "                            variable_dict['observed_survival'].astype(int), \n",
    "                            variable_dict['censoring'],\n",
    "                            epochs=50, \n",
    "                            verbose=False, \n",
    "                            batch_size=128\n",
    "                            )\n",
    "    mod_hcl = model_heavy_cens.model\n",
    "else:\n",
    "    mod_hcl = tf.keras.models.load_model('data/model_weights/model_heavy_censoring_large.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-20 17:15:10.664209: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/375 [..............................] - ETA: 6:52\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r  5/375 [..............................] - ETA: 6s  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r  9/375 [..............................] - ETA: 5s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 13/375 [>.............................] - ETA: 5s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 17/375 [>.............................] - ETA: 5s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 21/375 [>.............................] - ETA: 5s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 23/375 [>.............................] - ETA: 5s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 26/375 [=>............................] - ETA: 5s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 29/375 [=>............................] - ETA: 5s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 32/375 [=>............................] - ETA: 5s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 36/375 [=>............................] - ETA: 5s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 40/375 [==>...........................] - ETA: 5s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 44/375 [==>...........................] - ETA: 5s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 48/375 [==>...........................] - ETA: 5s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 52/375 [===>..........................] - ETA: 5s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 56/375 [===>..........................] - ETA: 5s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 60/375 [===>..........................] - ETA: 5s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 64/375 [====>.........................] - ETA: 4s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 68/375 [====>.........................] - ETA: 4s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 72/375 [====>.........................] - ETA: 4s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 76/375 [=====>........................] - ETA: 4s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 80/375 [=====>........................] - ETA: 4s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 84/375 [=====>........................] - ETA: 4s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 88/375 [======>.......................] - ETA: 4s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 92/375 [======>.......................] - ETA: 4s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 96/375 [======>.......................] - ETA: 4s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/375 [=======>......................] - ETA: 4s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r104/375 [=======>......................] - ETA: 4s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r108/375 [=======>......................] - ETA: 4s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r112/375 [=======>......................] - ETA: 3s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r116/375 [========>.....................] - ETA: 3s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r120/375 [========>.....................] - ETA: 3s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/375 [========>.....................] - ETA: 3s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r128/375 [=========>....................] - ETA: 3s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r132/375 [=========>....................] - ETA: 3s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r136/375 [=========>....................] - ETA: 3s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r140/375 [==========>...................] - ETA: 3s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r144/375 [==========>...................] - ETA: 3s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r148/375 [==========>...................] - ETA: 3s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r152/375 [===========>..................] - ETA: 3s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r156/375 [===========>..................] - ETA: 3s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r160/375 [===========>..................] - ETA: 3s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r164/375 [============>.................] - ETA: 3s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r168/375 [============>.................] - ETA: 3s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r172/375 [============>.................] - ETA: 2s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r175/375 [=============>................] - ETA: 2s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r179/375 [=============>................] - ETA: 2s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r183/375 [=============>................] - ETA: 2s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r187/375 [=============>................] - ETA: 2s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r191/375 [==============>...............] - ETA: 2s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r195/375 [==============>...............] - ETA: 2s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r199/375 [==============>...............] - ETA: 2s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r203/375 [===============>..............] - ETA: 2s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r207/375 [===============>..............] - ETA: 2s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r211/375 [===============>..............] - ETA: 2s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r215/375 [================>.............] - ETA: 2s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r219/375 [================>.............] - ETA: 2s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r223/375 [================>.............] - ETA: 2s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r227/375 [=================>............] - ETA: 2s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r231/375 [=================>............] - ETA: 2s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r235/375 [=================>............] - ETA: 2s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r239/375 [==================>...........] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r243/375 [==================>...........] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r247/375 [==================>...........] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r251/375 [===================>..........] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r255/375 [===================>..........] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r259/375 [===================>..........] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r263/375 [====================>.........] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r267/375 [====================>.........] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r271/375 [====================>.........] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r275/375 [=====================>........] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r279/375 [=====================>........] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r283/375 [=====================>........] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r287/375 [=====================>........] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r291/375 [======================>.......] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r295/375 [======================>.......] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r299/375 [======================>.......] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r303/375 [=======================>......] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r307/375 [=======================>......] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r311/375 [=======================>......] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r315/375 [========================>.....] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r319/375 [========================>.....] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r323/375 [========================>.....] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r327/375 [=========================>....] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r331/375 [=========================>....] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r335/375 [=========================>....] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r339/375 [==========================>...] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r343/375 [==========================>...] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r347/375 [==========================>...] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r351/375 [===========================>..] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r355/375 [===========================>..] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r359/375 [===========================>..] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r363/375 [============================>.] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r367/375 [============================>.] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r371/375 [============================>.] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r375/375 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r375/375 [==============================] - 6s 14ms/step\n"
     ]
    }
   ],
   "source": [
    "# Run predictions \n",
    "predictions_ckm_hc = mod_hcl.predict(variable_dict['features'])\n",
    "\n",
    "# Predictions are a list for each timeperiod, flatten and create exportable dataframe\n",
    "ckm_df = (pd.DataFrame(list(map(np.ravel, predictions_ckm_hc)))\n",
    "          .reset_index()\n",
    "          .rename(columns={'index':'timeline'}))\n",
    "\n",
    "# Avoid Python specific index issues\n",
    "ckm_df['timeline'] = ckm_df.timeline\n",
    "\n",
    "# Export\n",
    "ckm_df.to_csv('data/dependent_censoring/ckm_pred_heavy_censoring_larger_model.csv', \n",
    "              index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Manual\" approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_ = 3000\n",
    "seed_ = 42\n",
    "\n",
    "np.random.seed(seed_)\n",
    "x_1 = np.random.exponential(0.1, size=size_)\n",
    "x_2 = np.random.normal(10, np.sqrt(5), size=size_)\n",
    "x_3 = np.random.poisson(5, size=size_)\n",
    "\n",
    "features = np.array([x_1, x_2, x_3]).T\n",
    "\n",
    "# Arrange Targets\n",
    "survial_model = -3.14*x_1 + 0.318*x_2 + 2.72*x_3\n",
    "\n",
    "true_survival_time = gamma.rvs(survial_model, scale=1, random_state=seed_)\n",
    "ceiling_surv_ = np.ceil(true_survival_time)\n",
    "\n",
    "censoring_transformed = np.minimum(0.75*(survial_model/survial_model.max()),1)\n",
    "\n",
    "censored_instances = np.random.uniform(size=size_) > (censoring_transformed)\n",
    "censored_surv = [np.ceil(np.random.uniform()*val_) for val_ in ceiling_surv_[censored_instances]]\n",
    "\n",
    "observed_survival = ceiling_surv_.copy()\n",
    "observed_survival[censored_instances] = censored_surv\n",
    "\n",
    "variable_dict = dict({'true_survival': ceiling_surv_,\n",
    "                      'observed_survival': observed_survival, \n",
    "                      'censoring': censored_instances,\n",
    "                      'features' :  features})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_:\n",
    "        \n",
    "    # Set up model\n",
    "    total_periods = int(variable_dict['observed_survival'].max())\n",
    "\n",
    "    model_censoring = DeepKaplanMeier(total_periods)\n",
    "    model_censoring.compile_model((3, ), [12,12])\n",
    "\n",
    "    censoring_censroing = np.repeat(False, len(variable_dict['censoring']))\n",
    "\n",
    "\n",
    "    _, inverse_censoring_matrix = model_censoring.prepare_survival(variable_dict['observed_survival'].astype(int),\n",
    "                                                                variable_dict['censoring'])\n",
    "    censoring_matrix = 1-inverse_censoring_matrix\n",
    "\n",
    "    censoring_times = total_periods - censoring_matrix.sum(axis=1) + 1\n",
    "\n",
    "    # Fit model\n",
    "    model_censoring.fit_model(variable_dict['features'],\n",
    "                            censoring_times.astype(int), \n",
    "                            censoring_censroing,\n",
    "                            epochs=50, \n",
    "                            verbose=False, \n",
    "                            batch_size=64)\n",
    "\n",
    "    preds_censoring = model_censoring.model.predict(variable_dict['features'])\n",
    "    weight_matrix_censoring = np.hstack(preds_censoring).mean(axis=0) / np.hstack(preds_censoring)\n",
    "\n",
    "    total_periods = int(variable_dict['observed_survival'].max())\n",
    "\n",
    "    model_survival = SimpleDeepKaplanCensoring(total_periods)\n",
    "    model_survival.compile_model((3, ), [20,20])\n",
    "\n",
    "    model_survival.fit_model(variable_dict['features'],\n",
    "                                variable_dict['observed_survival'].astype(int), \n",
    "                                variable_dict['censoring'],\n",
    "                                weight_matrix_censoring,\n",
    "                                epochs=50, \n",
    "                                verbose=False, \n",
    "                                batch_size=256\n",
    "                                )\n",
    "\n",
    "    mod_manual = model_survival.model\n",
    "\n",
    "else:\n",
    "    mod_manual = tf.keras.models.load_model('data/model_weights/model_manual_survival.keras')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/94 [..............................] - ETA: 2s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 5/94 [>.............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 9/94 [=>............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r13/94 [===>..........................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r17/94 [====>.........................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r21/94 [=====>........................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/94 [======>.......................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/94 [========>.....................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33/94 [=========>....................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r37/94 [==========>...................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r41/94 [============>.................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r45/94 [=============>................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r49/94 [==============>...............] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r53/94 [===============>..............] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r57/94 [=================>............] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r61/94 [==================>...........] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r65/94 [===================>..........] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r69/94 [=====================>........] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r73/94 [======================>.......] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r77/94 [=======================>......] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r81/94 [========================>.....] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r85/94 [==========================>...] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r89/94 [===========================>..] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r93/94 [============================>.] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r94/94 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r94/94 [==============================] - 2s 18ms/step\n"
     ]
    }
   ],
   "source": [
    "# Run predictions \n",
    "predictions_ckm = mod_manual.predict(variable_dict['features'])\n",
    "\n",
    "# Predictions are a list for each timeperiod, flatten and create exportable dataframe\n",
    "ckm_df = (pd.DataFrame(list(map(np.ravel, predictions_ckm)))\n",
    "          .reset_index()\n",
    "          .rename(columns={'index':'timeline'}))\n",
    "\n",
    "# Avoid Python specific index issues\n",
    "ckm_df['timeline'] = ckm_df.timeline\n",
    "\n",
    "# Export\n",
    "ckm_df.to_csv('data/dependent_censoring/manually_corrected_version_dependent.csv', \n",
    "              index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bbbf41762ef44221e9bab1cb88f3143b98cae4bbdab9afd61221d8b0b6f6be23"
  },
  "kernelspec": {
   "display_name": "tens_env",
   "language": "python",
   "name": "tens_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12 | packaged by conda-forge | (default, Oct 12 2021, 21:21:17) \n[Clang 11.1.0 ]"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
